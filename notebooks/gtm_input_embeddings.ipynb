{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a6ddfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/germain/Documents/topic models/generalized_topic_model/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/germain/Documents/topic models/generalized_topic_model/notebooks/../gtm/utils.py:131: UserWarning: the longest document in your collection has 7237 words, the model instead truncates to 256 tokens.\n",
      "  warnings.warn(\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [06:42<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 57/57 [00:03<00:00, 15.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1\tIter   10\tLoss:2.8346760\tRec Loss:3.0282040\tMMD:-0.1935280\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter   20\tLoss:2.4371133\tRec Loss:2.6915181\tMMD:-0.2544048\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter   30\tLoss:2.2358239\tRec Loss:2.6835036\tMMD:-0.4476798\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter   40\tLoss:2.0736382\tRec Loss:2.6085024\tMMD:-0.5348641\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter   50\tLoss:1.9626981\tRec Loss:2.6347713\tMMD:-0.6720732\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter   60\tLoss:1.5540974\tRec Loss:2.2962251\tMMD:-0.7421277\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter   70\tLoss:1.6820028\tRec Loss:2.4477406\tMMD:-0.7657377\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter   80\tLoss:2.1455927\tRec Loss:2.9156623\tMMD:-0.7700695\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter   90\tLoss:1.5207143\tRec Loss:2.3155246\tMMD:-0.7948103\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter  100\tLoss:1.5107768\tRec Loss:2.2417207\tMMD:-0.7309439\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter  110\tLoss:1.6738231\tRec Loss:2.5012956\tMMD:-0.8274724\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter  120\tLoss:1.7513849\tRec Loss:2.5183375\tMMD:-0.7669526\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter  130\tLoss:1.3579191\tRec Loss:2.1967525\tMMD:-0.8388335\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter  140\tLoss:1.6418238\tRec Loss:2.4278941\tMMD:-0.7860703\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter  150\tLoss:1.5803208\tRec Loss:2.4043989\tMMD:-0.8240781\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter  160\tLoss:1.9121883\tRec Loss:2.6450579\tMMD:-0.7328696\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter  170\tLoss:1.6187483\tRec Loss:2.3436389\tMMD:-0.7248906\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter  180\tLoss:1.5375974\tRec Loss:2.2776546\tMMD:-0.7400573\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   1\tIter  190\tLoss:1.4770834\tRec Loss:2.2117004\tMMD:-0.7346171\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter   10\tLoss:2.1669812\tRec Loss:2.2243392\tMMD:-0.0573580\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter   20\tLoss:2.6003304\tRec Loss:2.6669850\tMMD:-0.0666546\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter   30\tLoss:1.9351661\tRec Loss:1.9857118\tMMD:-0.0505456\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter   40\tLoss:2.4518104\tRec Loss:2.5035329\tMMD:-0.0517226\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter   50\tLoss:2.4169664\tRec Loss:2.4511664\tMMD:-0.0342000\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter   60\tLoss:2.3755879\tRec Loss:2.4264467\tMMD:-0.0508588\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter   70\tLoss:2.3723876\tRec Loss:2.4019117\tMMD:-0.0295242\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter   80\tLoss:2.2495384\tRec Loss:2.3093667\tMMD:-0.0598283\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter   90\tLoss:2.1886854\tRec Loss:2.2251825\tMMD:-0.0364972\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter  100\tLoss:2.5734029\tRec Loss:2.6090312\tMMD:-0.0356284\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter  110\tLoss:1.7981457\tRec Loss:2.5689349\tMMD:-0.7707893\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter  120\tLoss:1.3673851\tRec Loss:2.3969595\tMMD:-1.0295744\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter  130\tLoss:1.4792571\tRec Loss:2.3282847\tMMD:-0.8490276\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter  140\tLoss:1.0291969\tRec Loss:1.9707260\tMMD:-0.9415292\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter  150\tLoss:1.4963441\tRec Loss:2.4641619\tMMD:-0.9678177\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter  160\tLoss:1.6378344\tRec Loss:2.6912849\tMMD:-1.0534505\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter  170\tLoss:1.4127526\tRec Loss:2.4521158\tMMD:-1.0393631\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter  180\tLoss:1.2667786\tRec Loss:2.3551650\tMMD:-1.0883864\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n",
      "Epoch   2\tIter  190\tLoss:1.6046182\tRec Loss:2.7196393\tMMD:-1.1150211\tSparsity_Loss:0.0000000\tPred_Loss:0.0000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/hansard_archive/hansard_speeches_processed.csv')\n",
    "df = df.sample(n=50000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # to avoid some warnings\n",
    "\n",
    "import sys\n",
    "sys.path.append('../gtm/')\n",
    "from corpus import GTMCorpus\n",
    "from gtm import GTM\n",
    "\n",
    "# Create a GTMCorpus object\n",
    "train_dataset = GTMCorpus(\n",
    "    df, \n",
    "    embeddings_type = \"SentenceTransformer\",\n",
    "    sbert_model_to_load = \"all-MiniLM-L6-v2\",\n",
    "    prevalence = \"~ party\", \n",
    "    content = \"~ party\",\n",
    "    max_seq_length = 256\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "tm = GTM(\n",
    "    train_dataset, \n",
    "    n_topics=20,\n",
    "    doc_topic_prior='dirichlet',\n",
    "    update_prior=True,\n",
    "    encoder_input = 'embeddings',\n",
    "    encoder_hidden_layers = [128,64],\n",
    "    num_epochs=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
