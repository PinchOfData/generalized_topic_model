{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../gtm/')\n",
    "sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shim-kojio/Desktop/internship/codes/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import pickle\n",
    "import numpy as np\n",
    "from random import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from corpus import GTMCorpus\n",
    "from patsy import dmatrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from corpus import GTMCorpus\n",
    "from gtm import GTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 20\n",
    "num_simulations = 5\n",
    "doc_args = {\n",
    "    \"num_content_covs\": 2,\n",
    "    \"num_prev_covs\": 2,\n",
    "    \"min_words\": 50,\n",
    "    \"max_words\": 100,\n",
    "    \"num_docs\": 10000,\n",
    "    \"voc_size\": 1000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I checked the estimation difference between gtm(dirichlet*sage) and lda\n",
    "- Mainly checked two parts\n",
    "  - the cossim scores of true and estimated doc_topic matrix\n",
    "    - pd.DataFrame of cossim_score \n",
    "      - like the pd.DataFramae of LDA, the diagonal elements should be higher than others. But, the element of GTM pd.DataFrame are all equally high.\n",
    "  - the first 5 docs' topic proportions (true and estimated doc_topic)\n",
    "    - lda estimated fairly well\n",
    "    - In gtm, even though true topic proportions are unbalanced, the estimated proportions are almost equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generating docs by GTM and estimating by GTM (dirichlet*SAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:53<00:00, 88.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1\tIter   10\tTotal Training Loss:2.5533109\tRec Loss:2.0433400\tMMD Loss:0.5099514\tSparsity Loss:0.0000197\tPred Loss:0.0000000\n",
      "Epoch   1\tIter   20\tTotal Training Loss:2.3821440\tRec Loss:2.0512173\tMMD Loss:0.3309071\tSparsity Loss:0.0000196\tPred Loss:0.0000000\n",
      "Epoch   1\tIter   30\tTotal Training Loss:2.4138753\tRec Loss:2.1047819\tMMD Loss:0.3090737\tSparsity Loss:0.0000197\tPred Loss:0.0000000\n",
      "Epoch   1\tIter   40\tTotal Training Loss:33.1842842\tRec Loss:34.1274490\tMMD Loss:-0.9434826\tSparsity Loss:0.0003173\tPred Loss:0.0000000\n",
      "Epoch   1\tTraining Loss:3.4876612\n",
      "Epoch   2\tIter   10\tTotal Training Loss:2.0876143\tRec Loss:2.0320191\tMMD Loss:0.0544250\tSparsity Loss:0.0011702\tPred Loss:0.0000000\n",
      "Epoch   2\tIter   20\tTotal Training Loss:2.0815988\tRec Loss:2.0218239\tMMD Loss:0.0586269\tSparsity Loss:0.0011480\tPred Loss:0.0000000\n",
      "Epoch   2\tIter   30\tTotal Training Loss:2.1210263\tRec Loss:2.0837359\tMMD Loss:0.0361493\tSparsity Loss:0.0011411\tPred Loss:0.0000000\n",
      "Epoch   2\tIter   40\tTotal Training Loss:36.0436707\tRec Loss:34.6322556\tMMD Loss:1.3930922\tSparsity Loss:0.0183237\tPred Loss:0.0000000\n",
      "Epoch   2\tTraining Loss:2.9561132\n",
      "Epoch   3\tIter   10\tTotal Training Loss:2.0973384\tRec Loss:2.0578170\tMMD Loss:0.0384779\tSparsity Loss:0.0010435\tPred Loss:0.0000000\n",
      "Epoch   3\tIter   20\tTotal Training Loss:2.1032131\tRec Loss:2.0466113\tMMD Loss:0.0556047\tSparsity Loss:0.0009970\tPred Loss:0.0000000\n",
      "Epoch   3\tIter   30\tTotal Training Loss:2.0353813\tRec Loss:1.9983820\tMMD Loss:0.0360209\tSparsity Loss:0.0009786\tPred Loss:0.0000000\n",
      "Epoch   3\tIter   40\tTotal Training Loss:32.9189491\tRec Loss:32.7026062\tMMD Loss:0.2007930\tSparsity Loss:0.0155506\tPred Loss:0.0000000\n",
      "Epoch   3\tTraining Loss:2.8482390\n",
      "Epoch   4\tIter   10\tTotal Training Loss:2.0317233\tRec Loss:2.0036573\tMMD Loss:0.0270997\tSparsity Loss:0.0009662\tPred Loss:0.0000000\n",
      "Epoch   4\tIter   20\tTotal Training Loss:2.0300009\tRec Loss:2.0043766\tMMD Loss:0.0247089\tSparsity Loss:0.0009152\tPred Loss:0.0000000\n",
      "Epoch   4\tIter   30\tTotal Training Loss:2.0385435\tRec Loss:2.0093355\tMMD Loss:0.0283166\tSparsity Loss:0.0008911\tPred Loss:0.0000000\n",
      "Epoch   4\tIter   40\tTotal Training Loss:31.1622448\tRec Loss:33.9870682\tMMD Loss:-2.8388913\tSparsity Loss:0.0140690\tPred Loss:0.0000000\n",
      "Epoch   4\tTraining Loss:2.7996820\n",
      "Epoch   5\tIter   10\tTotal Training Loss:2.0796270\tRec Loss:2.0395737\tMMD Loss:0.0391585\tSparsity Loss:0.0008950\tPred Loss:0.0000000\n",
      "Epoch   5\tIter   20\tTotal Training Loss:2.0529270\tRec Loss:2.0128145\tMMD Loss:0.0392678\tSparsity Loss:0.0008446\tPred Loss:0.0000000\n",
      "Epoch   5\tIter   30\tTotal Training Loss:2.0065279\tRec Loss:1.9882746\tMMD Loss:0.0174337\tSparsity Loss:0.0008196\tPred Loss:0.0000000\n",
      "Epoch   5\tIter   40\tTotal Training Loss:34.7514305\tRec Loss:34.0387039\tMMD Loss:0.6998413\tSparsity Loss:0.0128875\tPred Loss:0.0000000\n",
      "Epoch   5\tTraining Loss:2.8753140\n",
      "Epoch   6\tIter   10\tTotal Training Loss:2.0758243\tRec Loss:2.0399494\tMMD Loss:0.0350429\tSparsity Loss:0.0008318\tPred Loss:0.0000000\n",
      "Epoch   6\tIter   20\tTotal Training Loss:2.0418041\tRec Loss:2.0205762\tMMD Loss:0.0204418\tSparsity Loss:0.0007861\tPred Loss:0.0000000\n",
      "Epoch   6\tIter   30\tTotal Training Loss:2.0431106\tRec Loss:2.0162554\tMMD Loss:0.0260919\tSparsity Loss:0.0007633\tPred Loss:0.0000000\n",
      "Epoch   6\tIter   40\tTotal Training Loss:33.2069969\tRec Loss:35.3931351\tMMD Loss:-2.1981492\tSparsity Loss:0.0120106\tPred Loss:0.0000000\n",
      "Epoch   6\tTraining Loss:2.8317605\n",
      "Epoch   7\tIter   10\tTotal Training Loss:2.0374832\tRec Loss:2.0188680\tMMD Loss:0.0178337\tSparsity Loss:0.0007815\tPred Loss:0.0000000\n",
      "Epoch   7\tIter   20\tTotal Training Loss:2.0575106\tRec Loss:2.0486310\tMMD Loss:0.0081370\tSparsity Loss:0.0007428\tPred Loss:0.0000000\n",
      "Epoch   7\tIter   30\tTotal Training Loss:2.0667255\tRec Loss:2.0612326\tMMD Loss:0.0047710\tSparsity Loss:0.0007220\tPred Loss:0.0000000\n",
      "Epoch   7\tIter   40\tTotal Training Loss:30.6910820\tRec Loss:31.8492222\tMMD Loss:-1.1694729\tSparsity Loss:0.0113338\tPred Loss:0.0000000\n",
      "Epoch   7\tTraining Loss:2.7594016\n",
      "Epoch   8\tIter   10\tTotal Training Loss:2.0378294\tRec Loss:2.0086558\tMMD Loss:0.0284341\tSparsity Loss:0.0007395\tPred Loss:0.0000000\n",
      "Epoch   8\tIter   20\tTotal Training Loss:2.0239656\tRec Loss:1.9938073\tMMD Loss:0.0294524\tSparsity Loss:0.0007061\tPred Loss:0.0000000\n",
      "Epoch   8\tIter   30\tTotal Training Loss:2.0595694\tRec Loss:2.0443866\tMMD Loss:0.0144955\tSparsity Loss:0.0006872\tPred Loss:0.0000000\n",
      "Epoch   8\tIter   40\tTotal Training Loss:31.1347046\tRec Loss:29.8826675\tMMD Loss:1.2412469\tSparsity Loss:0.0107900\tPred Loss:0.0000000\n",
      "Epoch   8\tTraining Loss:2.7724700\n",
      "Epoch   9\tIter   10\tTotal Training Loss:2.0678482\tRec Loss:2.0374703\tMMD Loss:0.0296718\tSparsity Loss:0.0007060\tPred Loss:0.0000000\n",
      "Epoch   9\tIter   20\tTotal Training Loss:2.0345519\tRec Loss:2.0073302\tMMD Loss:0.0265443\tSparsity Loss:0.0006773\tPred Loss:0.0000000\n",
      "Epoch   9\tIter   30\tTotal Training Loss:2.0623255\tRec Loss:2.0392523\tMMD Loss:0.0224130\tSparsity Loss:0.0006601\tPred Loss:0.0000000\n",
      "Epoch   9\tIter   40\tTotal Training Loss:35.9878654\tRec Loss:33.7642975\tMMD Loss:2.2132006\tSparsity Loss:0.0103689\tPred Loss:0.0000000\n",
      "Epoch   9\tTraining Loss:2.8990173\n",
      "Epoch  10\tIter   10\tTotal Training Loss:2.0241499\tRec Loss:2.0131397\tMMD Loss:0.0103306\tSparsity Loss:0.0006795\tPred Loss:0.0000000\n",
      "Epoch  10\tIter   20\tTotal Training Loss:1.9997034\tRec Loss:1.9945524\tMMD Loss:0.0044974\tSparsity Loss:0.0006537\tPred Loss:0.0000000\n",
      "Epoch  10\tIter   30\tTotal Training Loss:2.0363357\tRec Loss:2.0200233\tMMD Loss:0.0156740\tSparsity Loss:0.0006384\tPred Loss:0.0000000\n",
      "Epoch  10\tIter   40\tTotal Training Loss:29.6567574\tRec Loss:30.7749214\tMMD Loss:-1.1282066\tSparsity Loss:0.0100418\tPred Loss:0.0000000\n",
      "Epoch  10\tTraining Loss:2.7282717\n"
     ]
    }
   ],
   "source": [
    "gtm_model_args = {\n",
    "    \"n_topics\": num_topics,\n",
    "    \"num_epochs\": 10,\n",
    "    \"update_prior\": True,\n",
    "    \"doc_topic_prior\": \"dirichlet\",\n",
    "    \"decoder_type\": \"sage\",\n",
    "    \"decoder_estimate_interactions\": True,\n",
    "    \"encoder_hidden_layers\":[512,256],\n",
    "    \"decoder_hidden_layers\":[300],\n",
    "    \"seed\":0\n",
    "    }\n",
    "\n",
    "\n",
    "### generating docs and creating true doc_topic dist\n",
    "df_true_dist_list, docs = generate_docs_by_gtm(\n",
    "    num_topics=20,\n",
    "    doc_topic_prior=gtm_model_args[\"doc_topic_prior\"],\n",
    "    decoder_type=gtm_model_args[\"decoder_type\"],\n",
    "    seed=0,\n",
    "    doc_args=doc_args,\n",
    "    is_output=False,\n",
    ")\n",
    "\n",
    "\n",
    "### estimating doc_topic dist\n",
    "df_test = pd.DataFrame(\n",
    "    data={\"doc\":docs[\"doc\"],\n",
    "    \"doc_clean\":docs[\"doc\"],\n",
    "    \"prevalence\": docs[\"prevalence_covariates\"],\n",
    "    \"content\": docs[\"content_covariates\"],\n",
    "    }\n",
    ")\n",
    "test_dataset = GTMCorpus(\n",
    "    df_test,\n",
    "    prevalence=\"~ prevalence\",\n",
    "    content=\"~ content\",\n",
    "    embeddings_type = None,\n",
    ")\n",
    "tm_test = GTM(\n",
    "    train_data = test_dataset,\n",
    "    **gtm_model_args\n",
    ")\n",
    "df_doc_topic_gtm = pd.DataFrame(\n",
    "        tm_test.get_doc_topic_distribution(test_dataset),\n",
    "        index=[\"Doc{}\".format(i) for i in range(doc_args[\"num_docs\"])],\n",
    "        columns=[\"Topic{}\".format(i) for i in range(num_topics)],\n",
    "    )\n",
    "\n",
    "true_df = df_true_dist_list[0]\n",
    "estimated_df = df_doc_topic_gtm\n",
    "\n",
    "\n",
    "### matching the columns of estimated doc_topic dist with those of true doc_topic dist by maximizing dot-product\n",
    "dotproduct_list = []\n",
    "for true_col in true_df.columns:\n",
    "    true_target_col = true_df.loc[:, true_col]\n",
    "    dotproduct_list_per_row = []\n",
    "    for col in estimated_df.columns:\n",
    "        target_col = estimated_df.loc[:, col]\n",
    "        dotproduct_list_per_row.append(np.dot(target_col, true_target_col))\n",
    "    dotproduct_list.append(dotproduct_list_per_row)\n",
    "\n",
    "corres_num_topic_dict = {}\n",
    "dotproduct_matrix = pd.DataFrame(dotproduct_list)\n",
    "\n",
    "true_topics, estimated_topics = linear_sum_assignment(-dotproduct_matrix)\n",
    "for true_topic, estimated_topic in zip(true_topics, estimated_topics):\n",
    "    corres_num_topic_dict[\"Topic{}\".format(true_topic)] = \"Topic{}\".format(\n",
    "        estimated_topic\n",
    "    )\n",
    "\n",
    "rearanged_df_gtm = estimated_df.loc[:, corres_num_topic_dict.values()]\n",
    "rearanged_df_gtm.columns = corres_num_topic_dict.keys()\n",
    "\n",
    "\n",
    "### calculating the cossim scores between true and estimated doc_topic dist\n",
    "cossim_score = []\n",
    "for true_col in true_df.columns:\n",
    "    score_per_topic = []\n",
    "    series_1 = true_df.loc[:, true_col]\n",
    "    for col in rearanged_df_gtm.columns:\n",
    "        series_2 = rearanged_df_gtm.loc[:, col]\n",
    "        score_per_topic.append(\n",
    "            np.dot(series_1.T, series_2)\n",
    "            / (np.linalg.norm(series_1) * np.linalg.norm(series_2)))\n",
    "    cossim_score.append(score_per_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.752271</td>\n",
       "      <td>0.751229</td>\n",
       "      <td>0.761298</td>\n",
       "      <td>0.751523</td>\n",
       "      <td>0.766565</td>\n",
       "      <td>0.751728</td>\n",
       "      <td>0.769060</td>\n",
       "      <td>0.737417</td>\n",
       "      <td>0.742410</td>\n",
       "      <td>0.759901</td>\n",
       "      <td>0.757959</td>\n",
       "      <td>0.751319</td>\n",
       "      <td>0.758603</td>\n",
       "      <td>0.744842</td>\n",
       "      <td>0.357952</td>\n",
       "      <td>0.766733</td>\n",
       "      <td>0.770552</td>\n",
       "      <td>0.746464</td>\n",
       "      <td>0.738831</td>\n",
       "      <td>0.747116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.780635</td>\n",
       "      <td>0.782160</td>\n",
       "      <td>0.790223</td>\n",
       "      <td>0.788325</td>\n",
       "      <td>0.800142</td>\n",
       "      <td>0.782879</td>\n",
       "      <td>0.797446</td>\n",
       "      <td>0.768733</td>\n",
       "      <td>0.772761</td>\n",
       "      <td>0.792489</td>\n",
       "      <td>0.788546</td>\n",
       "      <td>0.784901</td>\n",
       "      <td>0.791223</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>0.370273</td>\n",
       "      <td>0.802016</td>\n",
       "      <td>0.800565</td>\n",
       "      <td>0.774615</td>\n",
       "      <td>0.770629</td>\n",
       "      <td>0.775385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.689953</td>\n",
       "      <td>0.695435</td>\n",
       "      <td>0.698632</td>\n",
       "      <td>0.690806</td>\n",
       "      <td>0.708183</td>\n",
       "      <td>0.693315</td>\n",
       "      <td>0.707800</td>\n",
       "      <td>0.676871</td>\n",
       "      <td>0.681243</td>\n",
       "      <td>0.696759</td>\n",
       "      <td>0.700848</td>\n",
       "      <td>0.690445</td>\n",
       "      <td>0.693850</td>\n",
       "      <td>0.687467</td>\n",
       "      <td>0.319644</td>\n",
       "      <td>0.706978</td>\n",
       "      <td>0.709082</td>\n",
       "      <td>0.686702</td>\n",
       "      <td>0.684109</td>\n",
       "      <td>0.687682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.732471</td>\n",
       "      <td>0.737050</td>\n",
       "      <td>0.738326</td>\n",
       "      <td>0.735207</td>\n",
       "      <td>0.750650</td>\n",
       "      <td>0.734854</td>\n",
       "      <td>0.750052</td>\n",
       "      <td>0.718546</td>\n",
       "      <td>0.725164</td>\n",
       "      <td>0.739827</td>\n",
       "      <td>0.737919</td>\n",
       "      <td>0.737553</td>\n",
       "      <td>0.738475</td>\n",
       "      <td>0.726620</td>\n",
       "      <td>0.348640</td>\n",
       "      <td>0.749198</td>\n",
       "      <td>0.751511</td>\n",
       "      <td>0.727830</td>\n",
       "      <td>0.720367</td>\n",
       "      <td>0.722881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.562076</td>\n",
       "      <td>0.564055</td>\n",
       "      <td>0.568334</td>\n",
       "      <td>0.563814</td>\n",
       "      <td>0.580452</td>\n",
       "      <td>0.568154</td>\n",
       "      <td>0.575095</td>\n",
       "      <td>0.545004</td>\n",
       "      <td>0.559017</td>\n",
       "      <td>0.568083</td>\n",
       "      <td>0.570741</td>\n",
       "      <td>0.564188</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.555949</td>\n",
       "      <td>0.274184</td>\n",
       "      <td>0.577628</td>\n",
       "      <td>0.582347</td>\n",
       "      <td>0.554892</td>\n",
       "      <td>0.555823</td>\n",
       "      <td>0.555543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.740985</td>\n",
       "      <td>0.740720</td>\n",
       "      <td>0.749635</td>\n",
       "      <td>0.740810</td>\n",
       "      <td>0.760707</td>\n",
       "      <td>0.746254</td>\n",
       "      <td>0.756972</td>\n",
       "      <td>0.722755</td>\n",
       "      <td>0.731829</td>\n",
       "      <td>0.749482</td>\n",
       "      <td>0.746176</td>\n",
       "      <td>0.743371</td>\n",
       "      <td>0.744532</td>\n",
       "      <td>0.732666</td>\n",
       "      <td>0.352681</td>\n",
       "      <td>0.759527</td>\n",
       "      <td>0.760973</td>\n",
       "      <td>0.740236</td>\n",
       "      <td>0.728339</td>\n",
       "      <td>0.729854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.574094</td>\n",
       "      <td>0.571700</td>\n",
       "      <td>0.580500</td>\n",
       "      <td>0.573072</td>\n",
       "      <td>0.583160</td>\n",
       "      <td>0.573615</td>\n",
       "      <td>0.588645</td>\n",
       "      <td>0.555034</td>\n",
       "      <td>0.568584</td>\n",
       "      <td>0.578782</td>\n",
       "      <td>0.576006</td>\n",
       "      <td>0.573363</td>\n",
       "      <td>0.572290</td>\n",
       "      <td>0.564578</td>\n",
       "      <td>0.286820</td>\n",
       "      <td>0.585879</td>\n",
       "      <td>0.588224</td>\n",
       "      <td>0.566051</td>\n",
       "      <td>0.566185</td>\n",
       "      <td>0.565868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.824448</td>\n",
       "      <td>0.823203</td>\n",
       "      <td>0.831724</td>\n",
       "      <td>0.824320</td>\n",
       "      <td>0.843387</td>\n",
       "      <td>0.825834</td>\n",
       "      <td>0.843082</td>\n",
       "      <td>0.806591</td>\n",
       "      <td>0.812523</td>\n",
       "      <td>0.835337</td>\n",
       "      <td>0.830334</td>\n",
       "      <td>0.821272</td>\n",
       "      <td>0.828997</td>\n",
       "      <td>0.812183</td>\n",
       "      <td>0.396725</td>\n",
       "      <td>0.842093</td>\n",
       "      <td>0.846106</td>\n",
       "      <td>0.817856</td>\n",
       "      <td>0.809643</td>\n",
       "      <td>0.813436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.801860</td>\n",
       "      <td>0.804980</td>\n",
       "      <td>0.812203</td>\n",
       "      <td>0.805285</td>\n",
       "      <td>0.821021</td>\n",
       "      <td>0.808518</td>\n",
       "      <td>0.821257</td>\n",
       "      <td>0.788870</td>\n",
       "      <td>0.794947</td>\n",
       "      <td>0.813490</td>\n",
       "      <td>0.804607</td>\n",
       "      <td>0.804890</td>\n",
       "      <td>0.810602</td>\n",
       "      <td>0.793211</td>\n",
       "      <td>0.387303</td>\n",
       "      <td>0.822005</td>\n",
       "      <td>0.824738</td>\n",
       "      <td>0.796094</td>\n",
       "      <td>0.791242</td>\n",
       "      <td>0.790139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.612811</td>\n",
       "      <td>0.610599</td>\n",
       "      <td>0.617377</td>\n",
       "      <td>0.613851</td>\n",
       "      <td>0.627448</td>\n",
       "      <td>0.617110</td>\n",
       "      <td>0.624668</td>\n",
       "      <td>0.594216</td>\n",
       "      <td>0.604348</td>\n",
       "      <td>0.614943</td>\n",
       "      <td>0.615334</td>\n",
       "      <td>0.609933</td>\n",
       "      <td>0.619782</td>\n",
       "      <td>0.608199</td>\n",
       "      <td>0.292195</td>\n",
       "      <td>0.625188</td>\n",
       "      <td>0.629156</td>\n",
       "      <td>0.610355</td>\n",
       "      <td>0.601055</td>\n",
       "      <td>0.597505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.700720</td>\n",
       "      <td>0.702494</td>\n",
       "      <td>0.707097</td>\n",
       "      <td>0.704441</td>\n",
       "      <td>0.715330</td>\n",
       "      <td>0.706222</td>\n",
       "      <td>0.717527</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.696076</td>\n",
       "      <td>0.707901</td>\n",
       "      <td>0.709659</td>\n",
       "      <td>0.703414</td>\n",
       "      <td>0.709781</td>\n",
       "      <td>0.695136</td>\n",
       "      <td>0.345551</td>\n",
       "      <td>0.719505</td>\n",
       "      <td>0.722803</td>\n",
       "      <td>0.699025</td>\n",
       "      <td>0.688853</td>\n",
       "      <td>0.689874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.728352</td>\n",
       "      <td>0.726695</td>\n",
       "      <td>0.733760</td>\n",
       "      <td>0.731364</td>\n",
       "      <td>0.744143</td>\n",
       "      <td>0.729506</td>\n",
       "      <td>0.742765</td>\n",
       "      <td>0.715043</td>\n",
       "      <td>0.717027</td>\n",
       "      <td>0.737494</td>\n",
       "      <td>0.733164</td>\n",
       "      <td>0.734840</td>\n",
       "      <td>0.734569</td>\n",
       "      <td>0.717594</td>\n",
       "      <td>0.334627</td>\n",
       "      <td>0.741938</td>\n",
       "      <td>0.746002</td>\n",
       "      <td>0.723715</td>\n",
       "      <td>0.713903</td>\n",
       "      <td>0.718020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.675232</td>\n",
       "      <td>0.678631</td>\n",
       "      <td>0.682182</td>\n",
       "      <td>0.678087</td>\n",
       "      <td>0.695399</td>\n",
       "      <td>0.676306</td>\n",
       "      <td>0.694200</td>\n",
       "      <td>0.666151</td>\n",
       "      <td>0.671468</td>\n",
       "      <td>0.684333</td>\n",
       "      <td>0.688557</td>\n",
       "      <td>0.680694</td>\n",
       "      <td>0.679896</td>\n",
       "      <td>0.669485</td>\n",
       "      <td>0.328152</td>\n",
       "      <td>0.693116</td>\n",
       "      <td>0.697754</td>\n",
       "      <td>0.671403</td>\n",
       "      <td>0.669405</td>\n",
       "      <td>0.672259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.798454</td>\n",
       "      <td>0.802192</td>\n",
       "      <td>0.807342</td>\n",
       "      <td>0.799289</td>\n",
       "      <td>0.818017</td>\n",
       "      <td>0.801735</td>\n",
       "      <td>0.821049</td>\n",
       "      <td>0.784317</td>\n",
       "      <td>0.792994</td>\n",
       "      <td>0.809946</td>\n",
       "      <td>0.805731</td>\n",
       "      <td>0.800444</td>\n",
       "      <td>0.804466</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.390460</td>\n",
       "      <td>0.818572</td>\n",
       "      <td>0.822485</td>\n",
       "      <td>0.795793</td>\n",
       "      <td>0.788133</td>\n",
       "      <td>0.791981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.438741</td>\n",
       "      <td>0.447038</td>\n",
       "      <td>0.438082</td>\n",
       "      <td>0.445981</td>\n",
       "      <td>0.445837</td>\n",
       "      <td>0.444427</td>\n",
       "      <td>0.449045</td>\n",
       "      <td>0.429456</td>\n",
       "      <td>0.438713</td>\n",
       "      <td>0.446852</td>\n",
       "      <td>0.442196</td>\n",
       "      <td>0.438270</td>\n",
       "      <td>0.444186</td>\n",
       "      <td>0.440816</td>\n",
       "      <td>0.216925</td>\n",
       "      <td>0.451330</td>\n",
       "      <td>0.449480</td>\n",
       "      <td>0.436818</td>\n",
       "      <td>0.441332</td>\n",
       "      <td>0.433190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.546466</td>\n",
       "      <td>0.537738</td>\n",
       "      <td>0.546931</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>0.552138</td>\n",
       "      <td>0.542924</td>\n",
       "      <td>0.551507</td>\n",
       "      <td>0.534658</td>\n",
       "      <td>0.528892</td>\n",
       "      <td>0.544067</td>\n",
       "      <td>0.546819</td>\n",
       "      <td>0.536242</td>\n",
       "      <td>0.538968</td>\n",
       "      <td>0.530755</td>\n",
       "      <td>0.262421</td>\n",
       "      <td>0.552804</td>\n",
       "      <td>0.556364</td>\n",
       "      <td>0.534502</td>\n",
       "      <td>0.525213</td>\n",
       "      <td>0.538985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.517930</td>\n",
       "      <td>0.514516</td>\n",
       "      <td>0.523693</td>\n",
       "      <td>0.521258</td>\n",
       "      <td>0.529817</td>\n",
       "      <td>0.521558</td>\n",
       "      <td>0.530817</td>\n",
       "      <td>0.509224</td>\n",
       "      <td>0.511308</td>\n",
       "      <td>0.522261</td>\n",
       "      <td>0.524932</td>\n",
       "      <td>0.520975</td>\n",
       "      <td>0.523225</td>\n",
       "      <td>0.508602</td>\n",
       "      <td>0.241800</td>\n",
       "      <td>0.530005</td>\n",
       "      <td>0.531172</td>\n",
       "      <td>0.516761</td>\n",
       "      <td>0.512271</td>\n",
       "      <td>0.503751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.784912</td>\n",
       "      <td>0.789420</td>\n",
       "      <td>0.790567</td>\n",
       "      <td>0.787967</td>\n",
       "      <td>0.802870</td>\n",
       "      <td>0.788754</td>\n",
       "      <td>0.804318</td>\n",
       "      <td>0.773678</td>\n",
       "      <td>0.779032</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.790824</td>\n",
       "      <td>0.788341</td>\n",
       "      <td>0.792848</td>\n",
       "      <td>0.778761</td>\n",
       "      <td>0.374513</td>\n",
       "      <td>0.805257</td>\n",
       "      <td>0.808012</td>\n",
       "      <td>0.783067</td>\n",
       "      <td>0.775490</td>\n",
       "      <td>0.772982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.800624</td>\n",
       "      <td>0.802510</td>\n",
       "      <td>0.811041</td>\n",
       "      <td>0.804917</td>\n",
       "      <td>0.820018</td>\n",
       "      <td>0.804061</td>\n",
       "      <td>0.823199</td>\n",
       "      <td>0.787161</td>\n",
       "      <td>0.789777</td>\n",
       "      <td>0.811801</td>\n",
       "      <td>0.806337</td>\n",
       "      <td>0.806912</td>\n",
       "      <td>0.808839</td>\n",
       "      <td>0.795242</td>\n",
       "      <td>0.374782</td>\n",
       "      <td>0.821363</td>\n",
       "      <td>0.822638</td>\n",
       "      <td>0.797256</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.797363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.805916</td>\n",
       "      <td>0.805308</td>\n",
       "      <td>0.810926</td>\n",
       "      <td>0.803301</td>\n",
       "      <td>0.824530</td>\n",
       "      <td>0.808404</td>\n",
       "      <td>0.824552</td>\n",
       "      <td>0.784770</td>\n",
       "      <td>0.798326</td>\n",
       "      <td>0.813311</td>\n",
       "      <td>0.813437</td>\n",
       "      <td>0.808399</td>\n",
       "      <td>0.808860</td>\n",
       "      <td>0.795393</td>\n",
       "      <td>0.383851</td>\n",
       "      <td>0.825439</td>\n",
       "      <td>0.826244</td>\n",
       "      <td>0.798683</td>\n",
       "      <td>0.788953</td>\n",
       "      <td>0.797475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \n",
       "0   0.752271  0.751229  0.761298  0.751523  0.766565  0.751728  0.769060  \\\n",
       "1   0.780635  0.782160  0.790223  0.788325  0.800142  0.782879  0.797446   \n",
       "2   0.689953  0.695435  0.698632  0.690806  0.708183  0.693315  0.707800   \n",
       "3   0.732471  0.737050  0.738326  0.735207  0.750650  0.734854  0.750052   \n",
       "4   0.562076  0.564055  0.568334  0.563814  0.580452  0.568154  0.575095   \n",
       "5   0.740985  0.740720  0.749635  0.740810  0.760707  0.746254  0.756972   \n",
       "6   0.574094  0.571700  0.580500  0.573072  0.583160  0.573615  0.588645   \n",
       "7   0.824448  0.823203  0.831724  0.824320  0.843387  0.825834  0.843082   \n",
       "8   0.801860  0.804980  0.812203  0.805285  0.821021  0.808518  0.821257   \n",
       "9   0.612811  0.610599  0.617377  0.613851  0.627448  0.617110  0.624668   \n",
       "10  0.700720  0.702494  0.707097  0.704441  0.715330  0.706222  0.717527   \n",
       "11  0.728352  0.726695  0.733760  0.731364  0.744143  0.729506  0.742765   \n",
       "12  0.675232  0.678631  0.682182  0.678087  0.695399  0.676306  0.694200   \n",
       "13  0.798454  0.802192  0.807342  0.799289  0.818017  0.801735  0.821049   \n",
       "14  0.438741  0.447038  0.438082  0.445981  0.445837  0.444427  0.449045   \n",
       "15  0.546466  0.537738  0.546931  0.543750  0.552138  0.542924  0.551507   \n",
       "16  0.517930  0.514516  0.523693  0.521258  0.529817  0.521558  0.530817   \n",
       "17  0.784912  0.789420  0.790567  0.787967  0.802870  0.788754  0.804318   \n",
       "18  0.800624  0.802510  0.811041  0.804917  0.820018  0.804061  0.823199   \n",
       "19  0.805916  0.805308  0.810926  0.803301  0.824530  0.808404  0.824552   \n",
       "\n",
       "          7         8         9         10        11        12        13   \n",
       "0   0.737417  0.742410  0.759901  0.757959  0.751319  0.758603  0.744842  \\\n",
       "1   0.768733  0.772761  0.792489  0.788546  0.784901  0.791223  0.774411   \n",
       "2   0.676871  0.681243  0.696759  0.700848  0.690445  0.693850  0.687467   \n",
       "3   0.718546  0.725164  0.739827  0.737919  0.737553  0.738475  0.726620   \n",
       "4   0.545004  0.559017  0.568083  0.570741  0.564188  0.564270  0.555949   \n",
       "5   0.722755  0.731829  0.749482  0.746176  0.743371  0.744532  0.732666   \n",
       "6   0.555034  0.568584  0.578782  0.576006  0.573363  0.572290  0.564578   \n",
       "7   0.806591  0.812523  0.835337  0.830334  0.821272  0.828997  0.812183   \n",
       "8   0.788870  0.794947  0.813490  0.804607  0.804890  0.810602  0.793211   \n",
       "9   0.594216  0.604348  0.614943  0.615334  0.609933  0.619782  0.608199   \n",
       "10  0.687460  0.696076  0.707901  0.709659  0.703414  0.709781  0.695136   \n",
       "11  0.715043  0.717027  0.737494  0.733164  0.734840  0.734569  0.717594   \n",
       "12  0.666151  0.671468  0.684333  0.688557  0.680694  0.679896  0.669485   \n",
       "13  0.784317  0.792994  0.809946  0.805731  0.800444  0.804466  0.791667   \n",
       "14  0.429456  0.438713  0.446852  0.442196  0.438270  0.444186  0.440816   \n",
       "15  0.534658  0.528892  0.544067  0.546819  0.536242  0.538968  0.530755   \n",
       "16  0.509224  0.511308  0.522261  0.524932  0.520975  0.523225  0.508602   \n",
       "17  0.773678  0.779032  0.795626  0.790824  0.788341  0.792848  0.778761   \n",
       "18  0.787161  0.789777  0.811801  0.806337  0.806912  0.808839  0.795242   \n",
       "19  0.784770  0.798326  0.813311  0.813437  0.808399  0.808860  0.795393   \n",
       "\n",
       "          14        15        16        17        18        19  \n",
       "0   0.357952  0.766733  0.770552  0.746464  0.738831  0.747116  \n",
       "1   0.370273  0.802016  0.800565  0.774615  0.770629  0.775385  \n",
       "2   0.319644  0.706978  0.709082  0.686702  0.684109  0.687682  \n",
       "3   0.348640  0.749198  0.751511  0.727830  0.720367  0.722881  \n",
       "4   0.274184  0.577628  0.582347  0.554892  0.555823  0.555543  \n",
       "5   0.352681  0.759527  0.760973  0.740236  0.728339  0.729854  \n",
       "6   0.286820  0.585879  0.588224  0.566051  0.566185  0.565868  \n",
       "7   0.396725  0.842093  0.846106  0.817856  0.809643  0.813436  \n",
       "8   0.387303  0.822005  0.824738  0.796094  0.791242  0.790139  \n",
       "9   0.292195  0.625188  0.629156  0.610355  0.601055  0.597505  \n",
       "10  0.345551  0.719505  0.722803  0.699025  0.688853  0.689874  \n",
       "11  0.334627  0.741938  0.746002  0.723715  0.713903  0.718020  \n",
       "12  0.328152  0.693116  0.697754  0.671403  0.669405  0.672259  \n",
       "13  0.390460  0.818572  0.822485  0.795793  0.788133  0.791981  \n",
       "14  0.216925  0.451330  0.449480  0.436818  0.441332  0.433190  \n",
       "15  0.262421  0.552804  0.556364  0.534502  0.525213  0.538985  \n",
       "16  0.241800  0.530005  0.531172  0.516761  0.512271  0.503751  \n",
       "17  0.374513  0.805257  0.808012  0.783067  0.775490  0.772982  \n",
       "18  0.374782  0.821363  0.822638  0.797256  0.790347  0.797363  \n",
       "19  0.383851  0.825439  0.826244  0.798683  0.788953  0.797475  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cossim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 doc's true topic propotion is\n",
      "Topic0     0.036420\n",
      "Topic1     0.019133\n",
      "Topic2     0.004226\n",
      "Topic3     0.058087\n",
      "Topic4     0.004424\n",
      "Topic5     0.170350\n",
      "Topic6     0.045694\n",
      "Topic7     0.076254\n",
      "Topic8     0.110143\n",
      "Topic9     0.009770\n",
      "Topic10    0.138973\n",
      "Topic11    0.073326\n",
      "Topic12    0.000155\n",
      "Topic13    0.093822\n",
      "Topic14    0.002217\n",
      "Topic15    0.011145\n",
      "Topic16    0.004317\n",
      "Topic17    0.007991\n",
      "Topic18    0.048550\n",
      "Topic19    0.085002\n",
      "Name: Doc0, dtype: float64\n",
      "\n",
      "0 doc's estimated topic propotion is\n",
      "                0\n",
      "Topic0   0.077826\n",
      "Topic1   0.063446\n",
      "Topic2   0.051647\n",
      "Topic3   0.067337\n",
      "Topic4   0.068527\n",
      "Topic5   0.065586\n",
      "Topic6   0.049080\n",
      "Topic7   0.000175\n",
      "Topic8   0.032614\n",
      "Topic9   0.021860\n",
      "Topic10  0.058073\n",
      "Topic11  0.062439\n",
      "Topic12  0.038634\n",
      "Topic13  0.049347\n",
      "Topic14  0.049147\n",
      "Topic15  0.053196\n",
      "Topic16  0.042833\n",
      "Topic17  0.052828\n",
      "Topic18  0.057532\n",
      "Topic19  0.037874\n",
      "------------\n",
      "\n",
      "1 doc's true topic propotion is\n",
      "Topic0     0.080140\n",
      "Topic1     0.080401\n",
      "Topic2     0.008970\n",
      "Topic3     0.051392\n",
      "Topic4     0.013120\n",
      "Topic5     0.099699\n",
      "Topic6     0.015678\n",
      "Topic7     0.166390\n",
      "Topic8     0.063746\n",
      "Topic9     0.003052\n",
      "Topic10    0.034895\n",
      "Topic11    0.037859\n",
      "Topic12    0.034990\n",
      "Topic13    0.109840\n",
      "Topic14    0.000173\n",
      "Topic15    0.000127\n",
      "Topic16    0.000038\n",
      "Topic17    0.079189\n",
      "Topic18    0.052696\n",
      "Topic19    0.067604\n",
      "Name: Doc1, dtype: float64\n",
      "\n",
      "1 doc's estimated topic propotion is\n",
      "                0\n",
      "Topic0   0.081245\n",
      "Topic1   0.063596\n",
      "Topic2   0.052632\n",
      "Topic3   0.068553\n",
      "Topic4   0.070527\n",
      "Topic5   0.065732\n",
      "Topic6   0.049768\n",
      "Topic7   0.000110\n",
      "Topic8   0.032248\n",
      "Topic9   0.020414\n",
      "Topic10  0.057896\n",
      "Topic11  0.064667\n",
      "Topic12  0.038230\n",
      "Topic13  0.047949\n",
      "Topic14  0.048050\n",
      "Topic15  0.053271\n",
      "Topic16  0.041322\n",
      "Topic17  0.051862\n",
      "Topic18  0.054565\n",
      "Topic19  0.037363\n",
      "------------\n",
      "\n",
      "2 doc's true topic propotion is\n",
      "Topic0     0.036250\n",
      "Topic1     0.151272\n",
      "Topic2     0.030275\n",
      "Topic3     0.032886\n",
      "Topic4     0.099275\n",
      "Topic5     0.039557\n",
      "Topic6     0.000955\n",
      "Topic7     0.075016\n",
      "Topic8     0.123000\n",
      "Topic9     0.026510\n",
      "Topic10    0.012420\n",
      "Topic11    0.093720\n",
      "Topic12    0.009562\n",
      "Topic13    0.044681\n",
      "Topic14    0.034365\n",
      "Topic15    0.004066\n",
      "Topic16    0.006355\n",
      "Topic17    0.037455\n",
      "Topic18    0.119006\n",
      "Topic19    0.023372\n",
      "Name: Doc2, dtype: float64\n",
      "\n",
      "2 doc's estimated topic propotion is\n",
      "                0\n",
      "Topic0   0.075291\n",
      "Topic1   0.062768\n",
      "Topic2   0.051627\n",
      "Topic3   0.066746\n",
      "Topic4   0.067036\n",
      "Topic5   0.064871\n",
      "Topic6   0.049357\n",
      "Topic7   0.000273\n",
      "Topic8   0.034326\n",
      "Topic9   0.024278\n",
      "Topic10  0.056429\n",
      "Topic11  0.062799\n",
      "Topic12  0.040371\n",
      "Topic13  0.049478\n",
      "Topic14  0.049049\n",
      "Topic15  0.053884\n",
      "Topic16  0.044153\n",
      "Topic17  0.051618\n",
      "Topic18  0.057162\n",
      "Topic19  0.038484\n",
      "------------\n",
      "\n",
      "3 doc's true topic propotion is\n",
      "Topic0     0.056279\n",
      "Topic1     0.042770\n",
      "Topic2     0.007089\n",
      "Topic3     0.058062\n",
      "Topic4     0.000191\n",
      "Topic5     0.162634\n",
      "Topic6     0.004355\n",
      "Topic7     0.106021\n",
      "Topic8     0.017036\n",
      "Topic9     0.041497\n",
      "Topic10    0.002445\n",
      "Topic11    0.055938\n",
      "Topic12    0.000977\n",
      "Topic13    0.169878\n",
      "Topic14    0.000003\n",
      "Topic15    0.000029\n",
      "Topic16    0.022649\n",
      "Topic17    0.024165\n",
      "Topic18    0.209704\n",
      "Topic19    0.018276\n",
      "Name: Doc3, dtype: float64\n",
      "\n",
      "3 doc's estimated topic propotion is\n",
      "                0\n",
      "Topic0   0.072802\n",
      "Topic1   0.060995\n",
      "Topic2   0.051093\n",
      "Topic3   0.064649\n",
      "Topic4   0.065735\n",
      "Topic5   0.060338\n",
      "Topic6   0.048887\n",
      "Topic7   0.000765\n",
      "Topic8   0.038417\n",
      "Topic9   0.028170\n",
      "Topic10  0.055762\n",
      "Topic11  0.060676\n",
      "Topic12  0.042349\n",
      "Topic13  0.051132\n",
      "Topic14  0.049373\n",
      "Topic15  0.052204\n",
      "Topic16  0.044927\n",
      "Topic17  0.054176\n",
      "Topic18  0.056684\n",
      "Topic19  0.040869\n",
      "------------\n",
      "\n",
      "4 doc's true topic propotion is\n",
      "Topic0     7.384551e-03\n",
      "Topic1     1.245767e-01\n",
      "Topic2     2.492286e-02\n",
      "Topic3     9.896867e-02\n",
      "Topic4     1.535209e-02\n",
      "Topic5     3.569304e-02\n",
      "Topic6     1.142639e-01\n",
      "Topic7     1.087583e-01\n",
      "Topic8     6.940098e-02\n",
      "Topic9     6.134629e-02\n",
      "Topic10    5.410368e-02\n",
      "Topic11    4.890128e-02\n",
      "Topic12    2.920967e-03\n",
      "Topic13    6.626024e-02\n",
      "Topic14    4.074758e-07\n",
      "Topic15    3.456844e-02\n",
      "Topic16    9.200399e-04\n",
      "Topic17    4.834788e-02\n",
      "Topic18    3.835258e-02\n",
      "Topic19    4.495716e-02\n",
      "Name: Doc4, dtype: float64\n",
      "\n",
      "4 doc's estimated topic propotion is\n",
      "                0\n",
      "Topic0   0.075131\n",
      "Topic1   0.060393\n",
      "Topic2   0.051244\n",
      "Topic3   0.065431\n",
      "Topic4   0.067697\n",
      "Topic5   0.063537\n",
      "Topic6   0.048553\n",
      "Topic7   0.000366\n",
      "Topic8   0.035272\n",
      "Topic9   0.024448\n",
      "Topic10  0.058779\n",
      "Topic11  0.061358\n",
      "Topic12  0.040570\n",
      "Topic13  0.049650\n",
      "Topic14  0.049587\n",
      "Topic15  0.054342\n",
      "Topic16  0.044143\n",
      "Topic17  0.053851\n",
      "Topic18  0.056866\n",
      "Topic19  0.038785\n",
      "------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"{} doc's true topic propotion is\".format(i))\n",
    "    print(df_true_dist_list[0].iloc[i,:])\n",
    "    print()\n",
    "    print(\"{} doc's estimated topic propotion is\".format(i))\n",
    "    print(pd.DataFrame(tm_test.get_doc_topic_distribution(test_dataset)[i,:],index=[\"Topic{}\".format(j) for j in range(num_topics)]))\n",
    "    print(\"------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generating docs by LDA and estimating by LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:28<00:00, 67.44it/s]\n"
     ]
    }
   ],
   "source": [
    "num_topics = 20\n",
    "lda_model_args = {\n",
    "        \"update_every\": 1,\n",
    "        \"chunksize\": 100,\n",
    "        \"passes\": 10,\n",
    "        \"alpha\": 0.1,\n",
    "        \"eta\": 0.1,\n",
    "        \"per_word_topics\": True,\n",
    "        \"random_state\":0,\n",
    "}\n",
    "\n",
    "\n",
    "### generating docs and creating true doc_topic dist\n",
    "df_true_dist_list2, docs2 = generate_docs_by_lda(\n",
    "    num_topics=num_topics,\n",
    "    seed=0,\n",
    "    alpha=None,\n",
    "    beta=None,\n",
    "    doc_args = {\n",
    "        \"min_words\": 50,\n",
    "        \"max_words\": 100,\n",
    "        \"num_docs\": 10000,\n",
    "        \"voc_size\": 1000,\n",
    "    },\n",
    "    is_output=False,\n",
    ")\n",
    "\n",
    "\n",
    "### estimating doc_topic dist\n",
    "df_doc_topic_list2, df_topic_word_list2 = estimate_dist_by_lda(\n",
    "    data=docs2,\n",
    "    num_topics=num_topics,\n",
    "    voc_size=doc_args[\"voc_size\"],\n",
    "    model_args=lda_model_args,\n",
    "    is_output=False,\n",
    ")\n",
    "true_df = df_true_dist_list2[0]\n",
    "estimated_df = df_doc_topic_lda\n",
    "\n",
    "\n",
    "### matching the columns of estimated doc_topic dist with those of true doc_topic dist by maximizing dot-product\n",
    "score_list = []\n",
    "for true_col in true_df.columns:\n",
    "    true_target_col = true_df.loc[:, true_col]\n",
    "    score_list_per_row = []\n",
    "    for col in estimated_df.columns:\n",
    "        target_col = estimated_df.loc[:, col]\n",
    "        score_list_per_row.append(np.dot(target_col, true_target_col))\n",
    "    score_list.append(score_list_per_row)\n",
    "\n",
    "corres_num_topic_dict2 = {}\n",
    "score_matrix = pd.DataFrame(score_list)\n",
    "true_topics, estimated_topics = linear_sum_assignment(-score_matrix)\n",
    "\n",
    "for true_topic, estimated_topic in zip(true_topics, estimated_topics):\n",
    "    corres_num_topic_dict2[\"Topic{}\".format(true_topic)] = \"Topic{}\".format(\n",
    "        estimated_topic\n",
    "    )\n",
    "\n",
    "reanged_df_lda = estimated_df.loc[:, corres_num_topic_dict2.values()]\n",
    "reanged_df_lda.columns = corres_num_topic_dict2.keys()\n",
    "\n",
    "\n",
    "### calculating the cossim scores between true and estimated doc_topic dist\n",
    "cossim_score2 = []\n",
    "for true_col in true_df.columns:\n",
    "    inner_res = []\n",
    "    series_1 = true_df.loc[:, true_col]\n",
    "    for col in reanged_df_lda.columns:\n",
    "        series_2 = reanged_df_lda.loc[:, col]\n",
    "        inner_res.append(\n",
    "            np.dot(series_1.T, series_2)\n",
    "            / (np.linalg.norm(series_1) * np.linalg.norm(series_2)))\n",
    "    cossim_score2.append(inner_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966966</td>\n",
       "      <td>0.121119</td>\n",
       "      <td>0.099242</td>\n",
       "      <td>0.113975</td>\n",
       "      <td>0.111537</td>\n",
       "      <td>0.122923</td>\n",
       "      <td>0.112724</td>\n",
       "      <td>0.111915</td>\n",
       "      <td>0.113762</td>\n",
       "      <td>0.125090</td>\n",
       "      <td>0.109050</td>\n",
       "      <td>0.123663</td>\n",
       "      <td>0.119413</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.129806</td>\n",
       "      <td>0.109139</td>\n",
       "      <td>0.115162</td>\n",
       "      <td>0.109029</td>\n",
       "      <td>0.101731</td>\n",
       "      <td>0.117981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.114284</td>\n",
       "      <td>0.710227</td>\n",
       "      <td>0.127836</td>\n",
       "      <td>0.104996</td>\n",
       "      <td>0.120945</td>\n",
       "      <td>0.127966</td>\n",
       "      <td>0.119730</td>\n",
       "      <td>0.134096</td>\n",
       "      <td>0.130222</td>\n",
       "      <td>0.131551</td>\n",
       "      <td>0.097294</td>\n",
       "      <td>0.123424</td>\n",
       "      <td>0.145910</td>\n",
       "      <td>0.233797</td>\n",
       "      <td>0.187306</td>\n",
       "      <td>0.109312</td>\n",
       "      <td>0.103851</td>\n",
       "      <td>0.139006</td>\n",
       "      <td>0.100922</td>\n",
       "      <td>0.113350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.107157</td>\n",
       "      <td>0.127806</td>\n",
       "      <td>0.944978</td>\n",
       "      <td>0.108187</td>\n",
       "      <td>0.105977</td>\n",
       "      <td>0.117449</td>\n",
       "      <td>0.106199</td>\n",
       "      <td>0.158459</td>\n",
       "      <td>0.125088</td>\n",
       "      <td>0.127137</td>\n",
       "      <td>0.097659</td>\n",
       "      <td>0.133701</td>\n",
       "      <td>0.110055</td>\n",
       "      <td>0.186784</td>\n",
       "      <td>0.220020</td>\n",
       "      <td>0.111379</td>\n",
       "      <td>0.116482</td>\n",
       "      <td>0.152096</td>\n",
       "      <td>0.097550</td>\n",
       "      <td>0.115047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.098672</td>\n",
       "      <td>0.120999</td>\n",
       "      <td>0.112822</td>\n",
       "      <td>0.964052</td>\n",
       "      <td>0.140750</td>\n",
       "      <td>0.121427</td>\n",
       "      <td>0.107179</td>\n",
       "      <td>0.119113</td>\n",
       "      <td>0.113405</td>\n",
       "      <td>0.106576</td>\n",
       "      <td>0.103845</td>\n",
       "      <td>0.113477</td>\n",
       "      <td>0.115119</td>\n",
       "      <td>0.304165</td>\n",
       "      <td>0.123817</td>\n",
       "      <td>0.108146</td>\n",
       "      <td>0.107279</td>\n",
       "      <td>0.121264</td>\n",
       "      <td>0.107527</td>\n",
       "      <td>0.129112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.101198</td>\n",
       "      <td>0.129164</td>\n",
       "      <td>0.114105</td>\n",
       "      <td>0.121270</td>\n",
       "      <td>0.963232</td>\n",
       "      <td>0.108907</td>\n",
       "      <td>0.105027</td>\n",
       "      <td>0.134819</td>\n",
       "      <td>0.109554</td>\n",
       "      <td>0.118439</td>\n",
       "      <td>0.109410</td>\n",
       "      <td>0.131092</td>\n",
       "      <td>0.117738</td>\n",
       "      <td>0.296529</td>\n",
       "      <td>0.136671</td>\n",
       "      <td>0.119528</td>\n",
       "      <td>0.121940</td>\n",
       "      <td>0.116140</td>\n",
       "      <td>0.105116</td>\n",
       "      <td>0.115803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.102789</td>\n",
       "      <td>0.126431</td>\n",
       "      <td>0.114316</td>\n",
       "      <td>0.109599</td>\n",
       "      <td>0.097037</td>\n",
       "      <td>0.933576</td>\n",
       "      <td>0.102219</td>\n",
       "      <td>0.129103</td>\n",
       "      <td>0.112228</td>\n",
       "      <td>0.113907</td>\n",
       "      <td>0.113036</td>\n",
       "      <td>0.132567</td>\n",
       "      <td>0.121716</td>\n",
       "      <td>0.164539</td>\n",
       "      <td>0.142648</td>\n",
       "      <td>0.107807</td>\n",
       "      <td>0.119637</td>\n",
       "      <td>0.132677</td>\n",
       "      <td>0.112155</td>\n",
       "      <td>0.129122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.109315</td>\n",
       "      <td>0.137650</td>\n",
       "      <td>0.105657</td>\n",
       "      <td>0.135617</td>\n",
       "      <td>0.103332</td>\n",
       "      <td>0.120398</td>\n",
       "      <td>0.965932</td>\n",
       "      <td>0.135093</td>\n",
       "      <td>0.112604</td>\n",
       "      <td>0.117044</td>\n",
       "      <td>0.102968</td>\n",
       "      <td>0.120223</td>\n",
       "      <td>0.164455</td>\n",
       "      <td>0.161982</td>\n",
       "      <td>0.136564</td>\n",
       "      <td>0.117254</td>\n",
       "      <td>0.120136</td>\n",
       "      <td>0.120935</td>\n",
       "      <td>0.091208</td>\n",
       "      <td>0.136144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.113695</td>\n",
       "      <td>0.131437</td>\n",
       "      <td>0.127479</td>\n",
       "      <td>0.108811</td>\n",
       "      <td>0.108674</td>\n",
       "      <td>0.146671</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.946163</td>\n",
       "      <td>0.107229</td>\n",
       "      <td>0.101332</td>\n",
       "      <td>0.116161</td>\n",
       "      <td>0.119235</td>\n",
       "      <td>0.121796</td>\n",
       "      <td>0.163405</td>\n",
       "      <td>0.206608</td>\n",
       "      <td>0.125066</td>\n",
       "      <td>0.126246</td>\n",
       "      <td>0.135580</td>\n",
       "      <td>0.105432</td>\n",
       "      <td>0.144620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.095541</td>\n",
       "      <td>0.128628</td>\n",
       "      <td>0.128511</td>\n",
       "      <td>0.108916</td>\n",
       "      <td>0.104016</td>\n",
       "      <td>0.138914</td>\n",
       "      <td>0.112932</td>\n",
       "      <td>0.122005</td>\n",
       "      <td>0.965305</td>\n",
       "      <td>0.121792</td>\n",
       "      <td>0.100546</td>\n",
       "      <td>0.111954</td>\n",
       "      <td>0.114122</td>\n",
       "      <td>0.179128</td>\n",
       "      <td>0.131852</td>\n",
       "      <td>0.112340</td>\n",
       "      <td>0.111679</td>\n",
       "      <td>0.128807</td>\n",
       "      <td>0.108559</td>\n",
       "      <td>0.121694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.102897</td>\n",
       "      <td>0.130497</td>\n",
       "      <td>0.111768</td>\n",
       "      <td>0.097845</td>\n",
       "      <td>0.109773</td>\n",
       "      <td>0.114695</td>\n",
       "      <td>0.110479</td>\n",
       "      <td>0.114144</td>\n",
       "      <td>0.111315</td>\n",
       "      <td>0.961691</td>\n",
       "      <td>0.113749</td>\n",
       "      <td>0.106808</td>\n",
       "      <td>0.115097</td>\n",
       "      <td>0.167513</td>\n",
       "      <td>0.123342</td>\n",
       "      <td>0.109668</td>\n",
       "      <td>0.106812</td>\n",
       "      <td>0.115505</td>\n",
       "      <td>0.107501</td>\n",
       "      <td>0.112195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.101440</td>\n",
       "      <td>0.134566</td>\n",
       "      <td>0.147962</td>\n",
       "      <td>0.111666</td>\n",
       "      <td>0.121571</td>\n",
       "      <td>0.142516</td>\n",
       "      <td>0.099936</td>\n",
       "      <td>0.118554</td>\n",
       "      <td>0.114380</td>\n",
       "      <td>0.103267</td>\n",
       "      <td>0.961312</td>\n",
       "      <td>0.110494</td>\n",
       "      <td>0.123291</td>\n",
       "      <td>0.330305</td>\n",
       "      <td>0.159818</td>\n",
       "      <td>0.114401</td>\n",
       "      <td>0.113002</td>\n",
       "      <td>0.123862</td>\n",
       "      <td>0.107260</td>\n",
       "      <td>0.129579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.108434</td>\n",
       "      <td>0.138397</td>\n",
       "      <td>0.137803</td>\n",
       "      <td>0.129488</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>0.121147</td>\n",
       "      <td>0.102850</td>\n",
       "      <td>0.129196</td>\n",
       "      <td>0.110099</td>\n",
       "      <td>0.108469</td>\n",
       "      <td>0.104105</td>\n",
       "      <td>0.946839</td>\n",
       "      <td>0.107623</td>\n",
       "      <td>0.217057</td>\n",
       "      <td>0.130622</td>\n",
       "      <td>0.105466</td>\n",
       "      <td>0.114469</td>\n",
       "      <td>0.138456</td>\n",
       "      <td>0.128733</td>\n",
       "      <td>0.120827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.111266</td>\n",
       "      <td>0.142005</td>\n",
       "      <td>0.114166</td>\n",
       "      <td>0.108909</td>\n",
       "      <td>0.108642</td>\n",
       "      <td>0.144570</td>\n",
       "      <td>0.120322</td>\n",
       "      <td>0.202742</td>\n",
       "      <td>0.108086</td>\n",
       "      <td>0.120501</td>\n",
       "      <td>0.105084</td>\n",
       "      <td>0.131089</td>\n",
       "      <td>0.947736</td>\n",
       "      <td>0.193848</td>\n",
       "      <td>0.144479</td>\n",
       "      <td>0.118318</td>\n",
       "      <td>0.127997</td>\n",
       "      <td>0.116049</td>\n",
       "      <td>0.115221</td>\n",
       "      <td>0.120691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.091512</td>\n",
       "      <td>0.717902</td>\n",
       "      <td>0.111512</td>\n",
       "      <td>0.111040</td>\n",
       "      <td>0.107252</td>\n",
       "      <td>0.182748</td>\n",
       "      <td>0.119780</td>\n",
       "      <td>0.114866</td>\n",
       "      <td>0.108551</td>\n",
       "      <td>0.110873</td>\n",
       "      <td>0.114332</td>\n",
       "      <td>0.138306</td>\n",
       "      <td>0.122785</td>\n",
       "      <td>0.245207</td>\n",
       "      <td>0.135689</td>\n",
       "      <td>0.121805</td>\n",
       "      <td>0.148560</td>\n",
       "      <td>0.125809</td>\n",
       "      <td>0.110751</td>\n",
       "      <td>0.123079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.124955</td>\n",
       "      <td>0.102438</td>\n",
       "      <td>0.101537</td>\n",
       "      <td>0.107376</td>\n",
       "      <td>0.257048</td>\n",
       "      <td>0.106815</td>\n",
       "      <td>0.119725</td>\n",
       "      <td>0.121442</td>\n",
       "      <td>0.122694</td>\n",
       "      <td>0.109619</td>\n",
       "      <td>0.121609</td>\n",
       "      <td>0.109790</td>\n",
       "      <td>0.226405</td>\n",
       "      <td>0.913194</td>\n",
       "      <td>0.110132</td>\n",
       "      <td>0.117809</td>\n",
       "      <td>0.178269</td>\n",
       "      <td>0.133878</td>\n",
       "      <td>0.125611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.104230</td>\n",
       "      <td>0.139969</td>\n",
       "      <td>0.124681</td>\n",
       "      <td>0.109724</td>\n",
       "      <td>0.098494</td>\n",
       "      <td>0.123653</td>\n",
       "      <td>0.115114</td>\n",
       "      <td>0.149305</td>\n",
       "      <td>0.124420</td>\n",
       "      <td>0.118555</td>\n",
       "      <td>0.102688</td>\n",
       "      <td>0.107564</td>\n",
       "      <td>0.173187</td>\n",
       "      <td>0.414373</td>\n",
       "      <td>0.144286</td>\n",
       "      <td>0.959289</td>\n",
       "      <td>0.128929</td>\n",
       "      <td>0.130676</td>\n",
       "      <td>0.121051</td>\n",
       "      <td>0.113597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.099788</td>\n",
       "      <td>0.128457</td>\n",
       "      <td>0.121242</td>\n",
       "      <td>0.108608</td>\n",
       "      <td>0.106294</td>\n",
       "      <td>0.138532</td>\n",
       "      <td>0.107555</td>\n",
       "      <td>0.144792</td>\n",
       "      <td>0.111167</td>\n",
       "      <td>0.133289</td>\n",
       "      <td>0.104783</td>\n",
       "      <td>0.124747</td>\n",
       "      <td>0.118541</td>\n",
       "      <td>0.220968</td>\n",
       "      <td>0.145255</td>\n",
       "      <td>0.114668</td>\n",
       "      <td>0.958996</td>\n",
       "      <td>0.117718</td>\n",
       "      <td>0.102995</td>\n",
       "      <td>0.125498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.098093</td>\n",
       "      <td>0.127049</td>\n",
       "      <td>0.133972</td>\n",
       "      <td>0.114278</td>\n",
       "      <td>0.103681</td>\n",
       "      <td>0.130777</td>\n",
       "      <td>0.120411</td>\n",
       "      <td>0.135316</td>\n",
       "      <td>0.128819</td>\n",
       "      <td>0.114937</td>\n",
       "      <td>0.106140</td>\n",
       "      <td>0.131729</td>\n",
       "      <td>0.117547</td>\n",
       "      <td>0.201985</td>\n",
       "      <td>0.133987</td>\n",
       "      <td>0.119767</td>\n",
       "      <td>0.110042</td>\n",
       "      <td>0.949062</td>\n",
       "      <td>0.108372</td>\n",
       "      <td>0.111549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.110453</td>\n",
       "      <td>0.122509</td>\n",
       "      <td>0.132848</td>\n",
       "      <td>0.099188</td>\n",
       "      <td>0.105759</td>\n",
       "      <td>0.123274</td>\n",
       "      <td>0.091081</td>\n",
       "      <td>0.124020</td>\n",
       "      <td>0.113557</td>\n",
       "      <td>0.119594</td>\n",
       "      <td>0.103416</td>\n",
       "      <td>0.112489</td>\n",
       "      <td>0.121088</td>\n",
       "      <td>0.150094</td>\n",
       "      <td>0.167894</td>\n",
       "      <td>0.117320</td>\n",
       "      <td>0.116207</td>\n",
       "      <td>0.114325</td>\n",
       "      <td>0.962492</td>\n",
       "      <td>0.109267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.111126</td>\n",
       "      <td>0.135843</td>\n",
       "      <td>0.116380</td>\n",
       "      <td>0.100969</td>\n",
       "      <td>0.105732</td>\n",
       "      <td>0.136392</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>0.115811</td>\n",
       "      <td>0.121724</td>\n",
       "      <td>0.113174</td>\n",
       "      <td>0.121677</td>\n",
       "      <td>0.182239</td>\n",
       "      <td>0.108374</td>\n",
       "      <td>0.525754</td>\n",
       "      <td>0.132268</td>\n",
       "      <td>0.111770</td>\n",
       "      <td>0.129613</td>\n",
       "      <td>0.126311</td>\n",
       "      <td>0.103025</td>\n",
       "      <td>0.952555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \n",
       "0   0.966966  0.121119  0.099242  0.113975  0.111537  0.122923  0.112724  \\\n",
       "1   0.114284  0.710227  0.127836  0.104996  0.120945  0.127966  0.119730   \n",
       "2   0.107157  0.127806  0.944978  0.108187  0.105977  0.117449  0.106199   \n",
       "3   0.098672  0.120999  0.112822  0.964052  0.140750  0.121427  0.107179   \n",
       "4   0.101198  0.129164  0.114105  0.121270  0.963232  0.108907  0.105027   \n",
       "5   0.102789  0.126431  0.114316  0.109599  0.097037  0.933576  0.102219   \n",
       "6   0.109315  0.137650  0.105657  0.135617  0.103332  0.120398  0.965932   \n",
       "7   0.113695  0.131437  0.127479  0.108811  0.108674  0.146671  0.111111   \n",
       "8   0.095541  0.128628  0.128511  0.108916  0.104016  0.138914  0.112932   \n",
       "9   0.102897  0.130497  0.111768  0.097845  0.109773  0.114695  0.110479   \n",
       "10  0.101440  0.134566  0.147962  0.111666  0.121571  0.142516  0.099936   \n",
       "11  0.108434  0.138397  0.137803  0.129488  0.106100  0.121147  0.102850   \n",
       "12  0.111266  0.142005  0.114166  0.108909  0.108642  0.144570  0.120322   \n",
       "13  0.091512  0.717902  0.111512  0.111040  0.107252  0.182748  0.119780   \n",
       "14  0.099021  0.124955  0.102438  0.101537  0.107376  0.257048  0.106815   \n",
       "15  0.104230  0.139969  0.124681  0.109724  0.098494  0.123653  0.115114   \n",
       "16  0.099788  0.128457  0.121242  0.108608  0.106294  0.138532  0.107555   \n",
       "17  0.098093  0.127049  0.133972  0.114278  0.103681  0.130777  0.120411   \n",
       "18  0.110453  0.122509  0.132848  0.099188  0.105759  0.123274  0.091081   \n",
       "19  0.111126  0.135843  0.116380  0.100969  0.105732  0.136392  0.109453   \n",
       "\n",
       "          7         8         9         10        11        12        13   \n",
       "0   0.111915  0.113762  0.125090  0.109050  0.123663  0.119413  0.163900  \\\n",
       "1   0.134096  0.130222  0.131551  0.097294  0.123424  0.145910  0.233797   \n",
       "2   0.158459  0.125088  0.127137  0.097659  0.133701  0.110055  0.186784   \n",
       "3   0.119113  0.113405  0.106576  0.103845  0.113477  0.115119  0.304165   \n",
       "4   0.134819  0.109554  0.118439  0.109410  0.131092  0.117738  0.296529   \n",
       "5   0.129103  0.112228  0.113907  0.113036  0.132567  0.121716  0.164539   \n",
       "6   0.135093  0.112604  0.117044  0.102968  0.120223  0.164455  0.161982   \n",
       "7   0.946163  0.107229  0.101332  0.116161  0.119235  0.121796  0.163405   \n",
       "8   0.122005  0.965305  0.121792  0.100546  0.111954  0.114122  0.179128   \n",
       "9   0.114144  0.111315  0.961691  0.113749  0.106808  0.115097  0.167513   \n",
       "10  0.118554  0.114380  0.103267  0.961312  0.110494  0.123291  0.330305   \n",
       "11  0.129196  0.110099  0.108469  0.104105  0.946839  0.107623  0.217057   \n",
       "12  0.202742  0.108086  0.120501  0.105084  0.131089  0.947736  0.193848   \n",
       "13  0.114866  0.108551  0.110873  0.114332  0.138306  0.122785  0.245207   \n",
       "14  0.119725  0.121442  0.122694  0.109619  0.121609  0.109790  0.226405   \n",
       "15  0.149305  0.124420  0.118555  0.102688  0.107564  0.173187  0.414373   \n",
       "16  0.144792  0.111167  0.133289  0.104783  0.124747  0.118541  0.220968   \n",
       "17  0.135316  0.128819  0.114937  0.106140  0.131729  0.117547  0.201985   \n",
       "18  0.124020  0.113557  0.119594  0.103416  0.112489  0.121088  0.150094   \n",
       "19  0.115811  0.121724  0.113174  0.121677  0.182239  0.108374  0.525754   \n",
       "\n",
       "          14        15        16        17        18        19  \n",
       "0   0.129806  0.109139  0.115162  0.109029  0.101731  0.117981  \n",
       "1   0.187306  0.109312  0.103851  0.139006  0.100922  0.113350  \n",
       "2   0.220020  0.111379  0.116482  0.152096  0.097550  0.115047  \n",
       "3   0.123817  0.108146  0.107279  0.121264  0.107527  0.129112  \n",
       "4   0.136671  0.119528  0.121940  0.116140  0.105116  0.115803  \n",
       "5   0.142648  0.107807  0.119637  0.132677  0.112155  0.129122  \n",
       "6   0.136564  0.117254  0.120136  0.120935  0.091208  0.136144  \n",
       "7   0.206608  0.125066  0.126246  0.135580  0.105432  0.144620  \n",
       "8   0.131852  0.112340  0.111679  0.128807  0.108559  0.121694  \n",
       "9   0.123342  0.109668  0.106812  0.115505  0.107501  0.112195  \n",
       "10  0.159818  0.114401  0.113002  0.123862  0.107260  0.129579  \n",
       "11  0.130622  0.105466  0.114469  0.138456  0.128733  0.120827  \n",
       "12  0.144479  0.118318  0.127997  0.116049  0.115221  0.120691  \n",
       "13  0.135689  0.121805  0.148560  0.125809  0.110751  0.123079  \n",
       "14  0.913194  0.110132  0.117809  0.178269  0.133878  0.125611  \n",
       "15  0.144286  0.959289  0.128929  0.130676  0.121051  0.113597  \n",
       "16  0.145255  0.114668  0.958996  0.117718  0.102995  0.125498  \n",
       "17  0.133987  0.119767  0.110042  0.949062  0.108372  0.111549  \n",
       "18  0.167894  0.117320  0.116207  0.114325  0.962492  0.109267  \n",
       "19  0.132268  0.111770  0.129613  0.126311  0.103025  0.952555  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cossim_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 doc's true topic propotion is\n",
      "Topic0     6.968426e-04\n",
      "Topic1     1.779735e-03\n",
      "Topic2     5.236102e-05\n",
      "Topic3     7.236574e-05\n",
      "Topic4     2.846014e-01\n",
      "Topic5     2.720386e-02\n",
      "Topic6     9.833561e-04\n",
      "Topic7     9.197617e-13\n",
      "Topic8     3.208884e-18\n",
      "Topic9     2.288536e-02\n",
      "Topic10    4.768472e-01\n",
      "Topic11    1.231430e-04\n",
      "Topic12    1.505897e-10\n",
      "Topic13    1.030299e-09\n",
      "Topic14    4.210461e-04\n",
      "Topic15    4.721245e-07\n",
      "Topic16    1.096394e-04\n",
      "Topic17    1.542085e-18\n",
      "Topic18    2.075297e-03\n",
      "Topic19    1.821479e-01\n",
      "Name: Doc0, dtype: float64\n",
      "\n",
      "0 doc's estimated topic propotion is\n",
      "Topic0     0.000000\n",
      "Topic1     0.000000\n",
      "Topic2     0.000000\n",
      "Topic3     0.000000\n",
      "Topic4     0.249842\n",
      "Topic5     0.000000\n",
      "Topic6     0.000000\n",
      "Topic7     0.000000\n",
      "Topic8     0.055517\n",
      "Topic9     0.012565\n",
      "Topic10    0.318640\n",
      "Topic11    0.000000\n",
      "Topic12    0.000000\n",
      "Topic13    0.136678\n",
      "Topic14    0.054909\n",
      "Topic15    0.000000\n",
      "Topic16    0.000000\n",
      "Topic17    0.048990\n",
      "Topic18    0.027846\n",
      "Topic19    0.084009\n",
      "Name: Doc0, dtype: float64\n",
      "------------\n",
      "\n",
      "1 doc's true topic propotion is\n",
      "Topic0     1.127956e-05\n",
      "Topic1     8.540174e-03\n",
      "Topic2     5.431840e-03\n",
      "Topic3     5.312576e-08\n",
      "Topic4     3.049405e-06\n",
      "Topic5     1.136201e-03\n",
      "Topic6     4.944347e-08\n",
      "Topic7     4.416315e-03\n",
      "Topic8     1.520416e-04\n",
      "Topic9     3.223652e-09\n",
      "Topic10    4.639035e-03\n",
      "Topic11    2.695587e-08\n",
      "Topic12    4.840538e-01\n",
      "Topic13    4.900625e-01\n",
      "Topic14    1.023549e-06\n",
      "Topic15    1.622488e-06\n",
      "Topic16    3.305592e-06\n",
      "Topic17    3.689818e-13\n",
      "Topic18    1.066558e-03\n",
      "Topic19    4.811539e-04\n",
      "Name: Doc1, dtype: float64\n",
      "\n",
      "1 doc's estimated topic propotion is\n",
      "Topic0     0.000000\n",
      "Topic1     0.301011\n",
      "Topic2     0.000000\n",
      "Topic3     0.000000\n",
      "Topic4     0.000000\n",
      "Topic5     0.108752\n",
      "Topic6     0.000000\n",
      "Topic7     0.041114\n",
      "Topic8     0.000000\n",
      "Topic9     0.000000\n",
      "Topic10    0.000000\n",
      "Topic11    0.000000\n",
      "Topic12    0.443624\n",
      "Topic13    0.000000\n",
      "Topic14    0.000000\n",
      "Topic15    0.019808\n",
      "Topic16    0.067265\n",
      "Topic17    0.000000\n",
      "Topic18    0.000000\n",
      "Topic19    0.000000\n",
      "Name: Doc1, dtype: float64\n",
      "------------\n",
      "\n",
      "2 doc's true topic propotion is\n",
      "Topic0     2.369357e-03\n",
      "Topic1     6.351023e-06\n",
      "Topic2     9.330241e-10\n",
      "Topic3     2.431565e-06\n",
      "Topic4     2.841745e-03\n",
      "Topic5     1.207621e-02\n",
      "Topic6     2.721629e-02\n",
      "Topic7     5.351739e-07\n",
      "Topic8     3.121288e-03\n",
      "Topic9     1.800725e-07\n",
      "Topic10    1.884093e-04\n",
      "Topic11    1.654085e-02\n",
      "Topic12    7.515786e-02\n",
      "Topic13    1.663707e-01\n",
      "Topic14    1.675683e-01\n",
      "Topic15    2.375266e-02\n",
      "Topic16    4.933998e-01\n",
      "Topic17    1.104035e-04\n",
      "Topic18    4.002052e-18\n",
      "Topic19    9.276632e-03\n",
      "Name: Doc2, dtype: float64\n",
      "\n",
      "2 doc's estimated topic propotion is\n",
      "Topic0     0.038634\n",
      "Topic1     0.182876\n",
      "Topic2     0.000000\n",
      "Topic3     0.000000\n",
      "Topic4     0.000000\n",
      "Topic5     0.061061\n",
      "Topic6     0.000000\n",
      "Topic7     0.000000\n",
      "Topic8     0.000000\n",
      "Topic9     0.000000\n",
      "Topic10    0.000000\n",
      "Topic11    0.000000\n",
      "Topic12    0.123145\n",
      "Topic13    0.000000\n",
      "Topic14    0.144829\n",
      "Topic15    0.000000\n",
      "Topic16    0.406928\n",
      "Topic17    0.000000\n",
      "Topic18    0.000000\n",
      "Topic19    0.022821\n",
      "Name: Doc2, dtype: float64\n",
      "------------\n",
      "\n",
      "3 doc's true topic propotion is\n",
      "Topic0     3.639869e-03\n",
      "Topic1     9.325114e-10\n",
      "Topic2     1.620219e-03\n",
      "Topic3     1.748524e-03\n",
      "Topic4     6.226677e-03\n",
      "Topic5     1.502523e-01\n",
      "Topic6     1.108184e-04\n",
      "Topic7     5.193835e-02\n",
      "Topic8     4.580733e-11\n",
      "Topic9     1.547185e-02\n",
      "Topic10    2.488872e-09\n",
      "Topic11    5.746949e-09\n",
      "Topic12    3.793149e-10\n",
      "Topic13    5.266767e-02\n",
      "Topic14    5.610378e-05\n",
      "Topic15    1.219246e-02\n",
      "Topic16    1.725039e-02\n",
      "Topic17    6.675821e-01\n",
      "Topic18    2.178592e-20\n",
      "Topic19    1.924266e-02\n",
      "Name: Doc3, dtype: float64\n",
      "\n",
      "3 doc's estimated topic propotion is\n",
      "Topic0     0.000000\n",
      "Topic1     0.089829\n",
      "Topic2     0.000000\n",
      "Topic3     0.000000\n",
      "Topic4     0.000000\n",
      "Topic5     0.204345\n",
      "Topic6     0.000000\n",
      "Topic7     0.000000\n",
      "Topic8     0.000000\n",
      "Topic9     0.021994\n",
      "Topic10    0.000000\n",
      "Topic11    0.015374\n",
      "Topic12    0.000000\n",
      "Topic13    0.000000\n",
      "Topic14    0.000000\n",
      "Topic15    0.000000\n",
      "Topic16    0.020694\n",
      "Topic17    0.597575\n",
      "Topic18    0.033517\n",
      "Topic19    0.000000\n",
      "Name: Doc3, dtype: float64\n",
      "------------\n",
      "\n",
      "4 doc's true topic propotion is\n",
      "Topic0     1.840087e-03\n",
      "Topic1     1.277557e-07\n",
      "Topic2     1.237962e-01\n",
      "Topic3     3.011422e-05\n",
      "Topic4     3.753515e-02\n",
      "Topic5     1.832052e-08\n",
      "Topic6     5.124296e-03\n",
      "Topic7     6.856377e-01\n",
      "Topic8     2.425647e-03\n",
      "Topic9     5.371684e-02\n",
      "Topic10    1.251406e-04\n",
      "Topic11    6.248698e-08\n",
      "Topic12    6.107114e-02\n",
      "Topic13    4.616788e-07\n",
      "Topic14    5.402799e-13\n",
      "Topic15    1.083577e-05\n",
      "Topic16    7.382812e-05\n",
      "Topic17    1.045644e-16\n",
      "Topic18    2.614359e-02\n",
      "Topic19    2.468848e-03\n",
      "Name: Doc4, dtype: float64\n",
      "\n",
      "4 doc's estimated topic propotion is\n",
      "Topic0     0.098515\n",
      "Topic1     0.000000\n",
      "Topic2     0.140342\n",
      "Topic3     0.000000\n",
      "Topic4     0.000000\n",
      "Topic5     0.066431\n",
      "Topic6     0.051373\n",
      "Topic7     0.408949\n",
      "Topic8     0.000000\n",
      "Topic9     0.000000\n",
      "Topic10    0.000000\n",
      "Topic11    0.000000\n",
      "Topic12    0.047556\n",
      "Topic13    0.000000\n",
      "Topic14    0.063365\n",
      "Topic15    0.000000\n",
      "Topic16    0.000000\n",
      "Topic17    0.000000\n",
      "Topic18    0.056266\n",
      "Topic19    0.055371\n",
      "Name: Doc4, dtype: float64\n",
      "------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"{} doc's true topic propotion is\".format(i))\n",
    "    print(df_true_dist_list2[0].iloc[i,:])\n",
    "    print()\n",
    "    print(\"{} doc's estimated topic propotion is\".format(i))\n",
    "    print(reanged_df_lda.iloc[i,:])\n",
    "    print(\"------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
