{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6da6d8",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('../gtm/')\n",
    "sys.path.append('../simulation/')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from random import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from corpus import GTMCorpus\n",
    "from gtm import GTM\n",
    "from simulations import generate_docs_by_lda"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4685b313",
   "metadata": {},
   "source": [
    "cossim_list = []\n",
    "true_doc_topic_list = []\n",
    "estimated_doc_topic_list = []\n",
    "\n",
    "doc_topic_prior = 'dirichlet'\n",
    "update_prior = True\n",
    "num_epochs = 2\n",
    "num_iter = 100\n",
    "num_jobs = 4\n",
    "num_topics = 4\n",
    "num_covs = 5\n",
    "num_docs = 5000\n",
    "min_words = 50\n",
    "max_words = 100\n",
    "voc_size = 1000\n",
    "\n",
    "np.random.seed(42)\n",
    "lambda_ = np.random.rand(num_covs, num_topics)\n",
    "lambda_ = lambda_ - lambda_[:, 0][:, None]\n",
    "sqrt_sigma = np.random.rand(num_topics, num_topics)\n",
    "sigma = sqrt_sigma * sqrt_sigma.T\n",
    "\n",
    "dict_betas = {}\n",
    "for i in range(num_topics):\n",
    "    dict_betas[i] = {}\n",
    "    for c in range(num_covs):\n",
    "        dict_betas[i][c] = []\n",
    "\n",
    "for i in range(num_iter):\n",
    "    \n",
    "    gtm_model_args = {\n",
    "        \"n_topics\": num_topics,\n",
    "        \"num_epochs\":num_epochs,\n",
    "        \"update_prior\": update_prior,\n",
    "        \"w_prior\":None,\n",
    "        \"doc_topic_prior\": doc_topic_prior,\n",
    "        \"decoder_type\": \"mlp\",\n",
    "        \"encoder_hidden_layers\":[],\n",
    "        \"decoder_hidden_layers\":[],\n",
    "        \"decoder_bias\":False,\n",
    "        \"batch_size\":200,\n",
    "        \"print_every\":10000,\n",
    "        \"log_every\":100,\n",
    "        \"seed\":42\n",
    "        }\n",
    "    \n",
    "    df_true_dist_list_gtm, df_test = generate_docs_by_lda(\n",
    "        num_docs, \n",
    "        num_topics, \n",
    "        num_covs, \n",
    "        doc_topic_prior, \n",
    "        lambda_, \n",
    "        sigma,\n",
    "        min_words, \n",
    "        max_words, \n",
    "        voc_size, \n",
    "        num_jobs,\n",
    "        seed=i\n",
    "    )  \n",
    "    \n",
    "    test_dataset = GTMCorpus(\n",
    "        df_test,\n",
    "        prevalence = \"~ cov_0 + cov_1 + cov_2 + cov_3 + cov_4 - 1\"\n",
    "    )\n",
    "    tm_test = GTM(\n",
    "        train_data = test_dataset,\n",
    "        **gtm_model_args\n",
    "    )\n",
    "    df_doc_topic_gtm = pd.DataFrame(\n",
    "            tm_test.get_doc_topic_distribution(test_dataset),\n",
    "            index=[\"Doc{}\".format(i) for i in range(num_docs)],\n",
    "            columns=[\"Topic{}\".format(i) for i in range(num_topics)],\n",
    "        )\n",
    "    true_df = df_true_dist_list_gtm[0]\n",
    "    estimated_df = df_doc_topic_gtm\n",
    "\n",
    "    ### matching the columns of estimated doc_topic dist with those of true doc_topic dist by maximizing dot-product\n",
    "    score_list = []\n",
    "    for true_col in true_df.columns:\n",
    "        true_target_col = true_df.loc[:, true_col]\n",
    "        score_list_per_row = []\n",
    "        for col in estimated_df.columns:\n",
    "            target_col = estimated_df.loc[:, col]\n",
    "            score_list_per_row.append(np.dot(target_col, true_target_col))\n",
    "        score_list.append(score_list_per_row)\n",
    "    corres_num_topic_dict_gtm = {}\n",
    "    corres_num_topic_dict_gtm_bis = {}\n",
    "    score_matrix = pd.DataFrame(score_list)\n",
    "    true_topics, estimated_topics = linear_sum_assignment(-score_matrix)\n",
    "    for true_topic, estimated_topic in zip(true_topics, estimated_topics):\n",
    "        corres_num_topic_dict_gtm[\"Topic{}\".format(true_topic)] = \"Topic{}\".format(\n",
    "            estimated_topic\n",
    "        )\n",
    "        corres_num_topic_dict_gtm_bis[true_topic] = estimated_topic\n",
    "    reanged_df_gtm = estimated_df.loc[:, corres_num_topic_dict_gtm.values()]\n",
    "    reanged_df_gtm.columns = corres_num_topic_dict_gtm.keys()\n",
    "\n",
    "    true_doc_topic_list.append(true_df)\n",
    "    estimated_doc_topic_list.append(reanged_df_gtm)\n",
    "\n",
    "    lambda_hat = tm_test.prior.lambda_\n",
    "    lambda_hat = lambda_hat - lambda_hat[:, corres_num_topic_dict_gtm_bis[0]][:, None]\n",
    "\n",
    "    for i in range(num_topics):\n",
    "        for c in range(num_covs):\n",
    "            dict_betas[i][c] = dict_betas[i][c] + [lambda_hat[c, corres_num_topic_dict_gtm_bis[i]]]    \n",
    "\n",
    "    ### calculating the cossim scores between true and estimated doc_topic dist\n",
    "    cossim_score_gtm = []\n",
    "    for col in true_df.columns:\n",
    "        inner_res = []\n",
    "        series_1 = true_df.loc[:, col]\n",
    "        series_2 = reanged_df_gtm.loc[:, col]\n",
    "        cossim_score_gtm.append(\n",
    "            np.dot(series_1.T, series_2)\n",
    "            / (np.linalg.norm(series_1) * np.linalg.norm(series_2)))\n",
    "    cossim_list.append(cossim_score_gtm)\n",
    "    print(\"finished {} topics' simulation\".format(num_topics))\n",
    "    print()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3ea76",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(10,5),facecolor=\"white\", tight_layout=True)\n",
    "ax = fig.add_subplot(1, 1, 1,xlabel=\"Topic\", ylabel=\"Cosine Similarity\")\n",
    "df_score_res = pd.DataFrame(cossim_list,index=[\"Iter_{}\".format(i) for i in range(num_iter)])\n",
    "x = np.array(range(num_topics))\n",
    "ax.set_xticks(x)\n",
    "mean = df_score_res.mean(axis=0)\n",
    "std = df_score_res.std(axis=0)\n",
    "ax.bar(x, mean, yerr=std)\n",
    "#plt.savefig('doc_topic_proportions.png')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ce3474",
   "metadata": {},
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "i = 1\n",
    "c = 3\n",
    "\n",
    "data = dict_betas[i][c]\n",
    "kde = gaussian_kde(data)\n",
    "x = np.linspace(min(data) - 1, max(data) + 1, 1000)\n",
    "plt.fill_between(x, kde(x), alpha=0.5, color='lightblue', label='Kernel Density of Estimates')\n",
    "vertical_line_value = round(lambda_[c,i], 2)\n",
    "plt.axvline(x=vertical_line_value, color='black', linestyle='-', linewidth=2, label='True Value = {}'.format(vertical_line_value))\n",
    "plt.xlabel('Estimates')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc0291d",
   "metadata": {},
   "source": [
    "lambda_.round(2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd539d1d",
   "metadata": {},
   "source": [
    "lambda_hat.round(2)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
